#!/usr/bin/env Rscript

## script info:
	# This program can be used to speed up making an OTU table using
	# zero-radius OTUs (zOTUs) picked by unoise. Making a zOTU table
	# can be done by mapping all raw sequence reads back onto zOTU seeds,
	# but this is very time consuming. Since dereplicated reads are 
	# clustered at 100% identity, it's fair to use centroid sequences
	# in lieu of all raw reads. This speeds up the process greatly. 
	
	# Written by John L. Darcy, June 2017
	
	# Pipeline:
	
	# 0. Format raw read fasta headers to be in usearch format. 
		# this looks like >seqID;barcodelabel=sampleID
	# 1. Dereplicate raw reads
		# vsearch --derep_fulllength rawreads_renamed.fasta --output derep_seqs.fasta --uc derep_uctable.txt --sizeout
	# 2. Run unoise on dereplicated reads
		# usearch -unoise3 derep_seqs.fasta -minsize 4 -zotus zotu_seeds.fasta
	# 3. Map dereplicated reads onto zOTU seeds
		# vsearch --usearch_global derep_seqs.fasta --db zotu_seeds.fasta --id 0.97 --threads 24 --maxaccepts 0 --maxrejects 0 --uc unoise_uctable.txt
	# 4. Run this script
		# combine_uc.r -d derep_uctable.txt -u unoise_uctable.txt -t 20 -o zOTUtable.txt

## load in packages
	suppressPackageStartupMessages(require(optparse))
	suppressPackageStartupMessages(require(data.table))
	suppressPackageStartupMessages(require(parallel))

## make options for script

	option_list <- list(
		make_option(c("-d", "--derep_uc"), action="store", default=NA, type='character',
			help="Path to uc table produced by dereplication"), 
		make_option(c("-u", "--unoise_uc"), action="store", default=NA, type='character',
			help="Path to uc table produced by unoise"), 
		make_option(c("-o", "--output"), action="store", default=NA, type='character',
			help="Output filename for zOTU table"),
		make_option(c("-q", "--quiet"), action="store_true", default=FALSE, type='logical',
			help="Turns off satus messages and progress indicators"),
		make_option(c("-t", "--threads"), action="store", default=4, type='integer',
			help="Number of threads to use for parallel processing.")
	)
	
	# parse option arguments
	opt = parse_args(OptionParser(option_list=option_list))
	derep_uctable_filename <- opt$derep_uc
	unoise_uctable_filename <- opt$unoise_uc
	output_otutable_filename <- opt$output
	ncores <- opt$threads
	noisy <- !(opt$quiet)

## IMPORTANT NOTE: original sequence names (in derep_uc) need to contain barcodelabels. 
	# The dereplicated fasta header should look like this:
	# >uniqeid;barcodelabel=blahblah;size=1234

## define status message function
	msg <- function(x, noisy){
		if(noisy){print(x)}
	}

## define mclapply2 function
	# this is a version of mclapply that has a PROGRESS INDICATOR
	# THANKS SO MUCH to wannymahoots on stackoverflow, what a HERO.
	# https://stackoverflow.com/questions/10984556/is-there-way-to-track-progress-on-a-mclapply
	mclapply2 <- function(X, FUN, ..., 
		mc.preschedule = TRUE, mc.set.seed = TRUE,
		mc.silent = FALSE, mc.cores = getOption("mc.cores", 2L),
		mc.cleanup = TRUE, mc.allow.recursive = TRUE,
		mc.progress=TRUE, mc.style=3) 
	{
		if (!is.vector(X) || is.object(X)) X <- as.list(X)

		if (mc.progress) {
			f <- fifo(tempfile(), open="w+b", blocking=T)
			p <- parallel:::mcfork()
			pb <- txtProgressBar(0, length(X), style=mc.style)
			setTxtProgressBar(pb, 0) 
			progress <- 0
			if (inherits(p, "masterProcess")) {
				while (progress < length(X)) {
					readBin(f, "double")
					progress <- progress + 1
					setTxtProgressBar(pb, progress) 
				}
				cat("\n")
				parallel:::mcexit()
			}
		}
		tryCatch({
			result <- mclapply(X, ..., function(...) {
					res <- FUN(...)
					if (mc.progress) writeBin(1, f)
					res
				}, 
				mc.preschedule = mc.preschedule, mc.set.seed = mc.set.seed,
				mc.silent = mc.silent, mc.cores = mc.cores,
				mc.cleanup = mc.cleanup, mc.allow.recursive = mc.allow.recursive
			)

		}, finally = {
			if (mc.progress) close(f)
		})
		result
	}


## read in input files

	# in each uc table, col 9 is the sequence that is grouped into the zOTU/centroid in col 10.

	# derep_uc is the uc table generated by dereplication of raw reads.
	# it should be generated using something like,
	# vsearch --derep_fulllength allseqs_renamed.fasta --output derep_seqs.fasta --uc derep_uctable.txt --sizeout
	msg("Reading in derep uc file.", noisy)
	derep_uc <- fread(derep_uctable_filename, sep='\t', header=F, stringsAsFactors=F)

	# unoise_uc is the uc table generated by mapping dereplicated reads onto unoise seeds
	# it should be generated using something like,
	# vsearch --usearch global derep_seqs.fasta --db zotu_seeds.fasta --id 0.97 --threads 24 --maxaccepts 0 --maxrejects 0 --uc unoise_uctable.txt
	msg("Reading in unoise uc file.", noisy)
	unoise_uc <- fread(unoise_uctable_filename, sep='\t', header=F, stringsAsFactors=F)


## prune useless rows from uc tables

	# here I just keep H=hit rows
	# there are still self hits in there, with a *, but those are ignored later.
	unoise_uc <- unoise_uc[unoise_uc[[1]] == "H",]
	derep_uc <- derep_uc[derep_uc[[1]] == "H",]

## remove size annotations from unoise_uc if they aren't also in derep_uc

	removesize <- function(x){
		return(strsplit(x, split=";size=")[[1]][1])
	}
	if(grepl("size=", derep_uc[[10]][1]) == FALSE){
		msg("Fixing names in unoise uc file.", noisy)
		msg("If you are seeing this message, you may want to pre-process that file with awk in order to remove size annotations from the 9th column. Leave off the terminal semicolon while you're at it for maximum speedup. That said, this process is parallelized and goes pretty fast.", noisy)
		unoise_uc[[9]] <- simplify2array(mclapply2(X=unoise_uc[[9]], FUN=removesize, mc.cores=ncores, mc.progress=noisy))
	}

## remove trailing semicolons from all columns where they could be (everything but zOTUs column)

	# this is faster than adding them, and it's really important later that all names match up.
	# here I assume that columns have unoform format, i.e. no misture of terminal ; and lack thereof.
	lastchar <- function(x){
		return(tail(strsplit(x, "")[[1]], 1))
	}
	removelastchar <- function(x){
		return(gsub('.{1}$', '', x))
	}
	if(lastchar(derep_uc[[9]][[1]]) == ";"){
		msg("Removing terminal semicolons from derep uc column 9.", noisy)
		derep_uc[[9]] <- removelastchar(derep_uc[[9]])
	}
	if(lastchar(derep_uc[[10]][[1]]) == ";"){
		msg("Removing terminal semicolons from derep uc column 10.", noisy)
		derep_uc[[10]] <- removelastchar(derep_uc[[10]])
	}
	if(lastchar(unoise_uc[[9]][[1]]) == ";"){
		msg("Removing terminal semicolons from unoise uc column 9.", noisy)
		unoise_uc[[9]] <- removelastchar(unoise_uc[[9]])
	}

## make vector of unique zOTU names

	zOTU_names <- unique(unoise_uc[[10]])
	nzOTUs <- length(zOTU_names)

## make vector of sampleids for derep_uc

	# since each row of derep_uc corresponds to one hit, that hit has a sample associated with it.
	# this function takes a usearch format label and returns the sampleid ("barcodelabel")
	get_sampleid <- function(x){
		return(gsub(pattern=".*barcodelabel=(.*);?;?", replacement="\\1", x))
	}
	
	# apply that function to all the sequence IDs, in parallel
	msg("Extracting sampleIDs from sequence names.", noisy)
	derep_uc_sampleids <- simplify2array(mclapply2(X=derep_uc[[9]], FUN=get_sampleid, mc.cores=ncores, mc.progress=noisy))
	
	# get sampleids from centroids in advance
	msg("Extracting centroid sampleIDs.", noisy)
	centroid_sampleids <- simplify2array(mclapply2(X=unoise_uc[[9]], FUN=get_sampleid, mc.cores=ncores, mc.progress=noisy))

	# unique sampleids for iteration
	derep_uc_sampleids_unique <- unique(derep_uc_sampleids)
	derep_uc_sampleids_unique <- derep_uc_sampleids_unique[order(derep_uc_sampleids_unique)]

## Calculate final zOTU abundances

	msg("Calculating final zOTU abundances.", noisy)

	# make empty list, just because it's a habit of mine
	zOTU_vec_list <- list(0)


	# Function to get a row of an OTU table given the OTU name
	# this function is DANGEROUS, because it uses objects in the global namespace
	# without taking them as arguments. This is usually a no-no, but I'm doing it
	# so that when the function is parallelized, it doesn't use ALL THE RAM. 
	# I tried using "big.matrix" from "bigmemory" package, and it was worse,
	# even AFTER aliasing all of the inputs. 
	# note that the function does NOT write to these objects.
	# In this function, i refers to the zOTU itself. Originally a loop (blegh).
	get_zOTU_row <- function(zOTU){
		# find which derep centroids are within zOTU_i, get their sampleids too
		zOTU_rowsTF <- unoise_uc[[10]] == zOTU
		centroids_i <- unoise_uc[[9]] [zOTU_rowsTF]
		
		# get all sampleids of original sequences within those centroids (incl. centroids themselves)
		sampids_i <- c(derep_uc_sampleids[derep_uc[[10]] %in% centroids_i], centroid_sampleids [zOTU_rowsTF])
		
		# make sampids_i a factor so that table returns empty fields
		# this makes it work when an OTU isn't observed in a sample.
		# note that same derep_uc_sampleids_unique is used later as the colnames for the zOTU table
		sampids_i <- factor(sampids_i, levels=derep_uc_sampleids_unique)
		
		# make otu table row. table() will be sorted in the same order as derep_uc_sampleids_unique.
		return(as.numeric(table(sampids_i)))
	}
	
	# use above function to calculate zOTU abundances by sample
	zOTU_vec_list <- mclapply2(X=zOTU_names, FUN=get_zOTU_row, mc.cores=ncores, mc.progress=noisy)

## make zOTU table and write to file
	msg("Writing output to file.", noisy)

	# transform list of vectors to matrix
	zOTU_table <- t(simplify2array(zOTU_vec_list))

	# add column names for sampleIDs
	colnames(zOTU_table) <- derep_uc_sampleids_unique

	# add column for zOTU labels (NOT rownames - R won't print a header for rownames)
	zOTU_table <- data.table("SampleID"=zOTU_names, zOTU_table)

	# write out result
	fwrite(zOTU_table, file=output_otutable_filename, quote=F, row.names=F, sep='\t')

## all done
	msg("All done. Thanks for using my code, I hope it worked for you! Maybe cite my github page?", noisy)
	msg("(https://github.com/darcyj/combine_uc)", noisy)
	









